{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de53cd8a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb1ed6f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # either 3 or 6\n",
    "\n",
    "from data_generators import *\n",
    "from utils import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3a88d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1365\n",
      "1370\n"
     ]
    }
   ],
   "source": [
    "# setup generators / data loaders for training and validation\n",
    "\n",
    "# we'll make the training data loader in the training loop,\n",
    "# since we need to update some of the examples used each epoch\n",
    "source_train_gen = TrainGenerator(\"mouse\", \"CTCF\")\n",
    "target_train_gen = TrainGenerator(\"human\", \"CTCF\")\n",
    "\n",
    "source_val_gen = ValGenerator(\"mouse\", \"CTCF\")\n",
    "# using a batch size of 1 here because the generator returns\n",
    "# many examples in each batch\n",
    "source_val_data_loader = DataLoader(source_val_gen, batch_size = 1, shuffle = False)\n",
    "\n",
    "target_val_gen = ValGenerator(\"human\", \"CTCF\")\n",
    "target_val_data_loader = DataLoader(target_val_gen, batch_size = 1, shuffle = False) # why would shuffle=True mess with the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "285fd726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(torch.nn.Module):\n",
    "    def __init__(self, alpha1=1., alpha2=0., summary_writer=None):\n",
    "        super(BasicModel, self).__init__()\n",
    "        self.input_seq_len = 500\n",
    "        num_conv_filters = 240\n",
    "        lstm_hidden_units = 32\n",
    "        fc_layer1_units = 1024\n",
    "        fc_layer2_units = 512\n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "        \n",
    "        \n",
    "        # Defining the layers to go into our model\n",
    "        # (see the forward function for how they fit together)\n",
    "        self.conv = torch.nn.Conv1d(4, num_conv_filters, kernel_size=20, padding=0)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.maxpool = torch.nn.MaxPool1d(15, stride=15, padding=0)\n",
    "        self.lstm = torch.nn.LSTM(input_size=num_conv_filters,\n",
    "                                  hidden_size=lstm_hidden_units,\n",
    "                                  batch_first=True)\n",
    "        self.fc1 = torch.nn.Linear(in_features=lstm_hidden_units,\n",
    "                                   out_features=fc_layer1_units)\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "        self.fc2 = torch.nn.Linear(in_features=fc_layer1_units,\n",
    "                                   out_features=fc_layer2_units)\n",
    "        self.fc_final = torch.nn.Linear(in_features=fc_layer2_units,\n",
    "                                        out_features=1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.BCE_loss = torch.nn.BCELoss()\n",
    "\n",
    "        # We'll store performance metrics during training in these lists\n",
    "        self.train_loss_by_epoch = []\n",
    "        self.train_BCE_loss_by_epoch = []\n",
    "        self.train_CORAL_loss_by_epoch = []\n",
    "        self.source_val_loss_by_epoch = []\n",
    "        self.source_val_auprc_by_epoch = []\n",
    "        self.target_val_loss_by_epoch = []\n",
    "        self.target_val_auprc_by_epoch = []\n",
    "\n",
    "        # We'll record the best model we've seen yet each epoch\n",
    "        self.best_state_so_far = self.state_dict()\n",
    "        self.best_auprc_so_far = 1\n",
    "\n",
    "        # self.norm_diff = lambda A, B: [torch.linalg.norm(a - b) for (a,b) in zip(A,B)]\n",
    "        # self.cov = lambda data: torch_cov(torch.max(self.conv(data.squeeze().cuda()), 2).values.T)\n",
    "    \n",
    "    def covariance(self, data):\n",
    "        # let's hope that this pytorch implementation of torch_cov is differentiable\n",
    "        # see utils.py\n",
    "        return torch_cov(torch.max(self.conv(data.squeeze().cuda()), 2).values.T)\n",
    "    \n",
    "    def norm_diff(self, A, B):\n",
    "        return torch.linalg.norm(A - B, axis=1)\n",
    "    \n",
    "    def loader_to_generator(self, data_loader):\n",
    "        for batch in data_loader:\n",
    "            yield batch\n",
    "        # TODO check that each batch is the same as previous\n",
    "\n",
    "    def CORAL_loss(self, src_batch, tgt_gen, convolve):\n",
    "        # TODO need to handle case where we have more source than target data and next() returns None\n",
    "        tgt_batch, tgt_labels = next(tgt_gen)\n",
    "        a = self.covariance(src_batch) #, self.conv)\n",
    "        b = self.covariance(tgt_batch) #, self.conv)\n",
    "        d = a.shape[0]\n",
    "        loss = self.norm_diff(a, b) / (4 * d * d)\n",
    "#         loss = torch.tensor(self.norm_diff(a, b)).cuda() / (4 * d * d)\n",
    "        return torch.sum(loss) # TODO sum? mean?\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # return (self.conv(X))\n",
    "        X_1 = self.relu(self.conv(X))\n",
    "        # LSTM is expecting input of shape (batches, seq_len, conv_filters)\n",
    "        X_2 = self.maxpool(X_1).permute(0, 2, 1)\n",
    "        X_3, _ = self.lstm(X_2)\n",
    "        X_4 = X_3[:, -1]  # only need final output of LSTM\n",
    "        X_5 = self.relu(self.fc1(X_4))\n",
    "        X_6 = self.dropout(X_5)\n",
    "        X_7 = self.sigmoid(self.fc2(X_6))\n",
    "        y = self.sigmoid(self.fc_final(X_7)).squeeze()\n",
    "        return y\n",
    "    \n",
    "    def validation(self, data_loader): \n",
    "        # only run this within torch.no_grad() context!\n",
    "        losses = []\n",
    "        preds = []\n",
    "        labels = []\n",
    "        for seqs_onehot_batch, labels_batch in tqdm(data_loader):\n",
    "            # push batch through model, get predictions, calculate loss\n",
    "            preds_batch = self(seqs_onehot_batch.squeeze().cuda())\n",
    "            labels_batch = labels_batch.squeeze()\n",
    "            loss_batch = self.BCE_loss(preds_batch, labels_batch.cuda())\n",
    "            losses.append(loss_batch.item())\n",
    "\n",
    "            # storing labels + preds for auPRC calculation later\n",
    "            labels.extend(labels_batch.detach().numpy())  \n",
    "            preds.extend(preds_batch.cpu().detach().numpy())\n",
    "            \n",
    "        return np.array(losses), np.array(preds), np.array(labels)\n",
    "\n",
    "    def CORAL_loss_validation(self, source_val_data_loader, target_val_data_loader):\n",
    "        losses = []\n",
    "        tgt_gen = self.loader_to_generator(target_val_data_loader)\n",
    "        \n",
    "        for seqs_onehot_batch, labels_batch in tqdm(source_val_data_loader):\n",
    "            loss_batch = CORAL_loss(seqs_onehot_batch, tgt_gen, self.conv)\n",
    "            losses.append(loss_batch)\n",
    "        return torch.tensor(losses)\n",
    "    \n",
    "#         src_gen = loader_to_generator(source_val_data_loader)\n",
    "#         tgt_gen = loader_to_generator(target_val_data_loader)\n",
    "#         src_batch,_ = next(src_gen)\n",
    "#         tgt_batch,_ = next(tgt_gen)\n",
    "#         while src_batch is not None and tgt_batch is not None:\n",
    "#             CORAL_loss_batch = self.alpha * CORAL_loss(src_batch.squeeze().cuda(), self.conv)\n",
    "#             CORAL_losses.append(CORAL_loss_batch.item())\n",
    "#             src_batch,_ = next(src_gen)\n",
    "#             tgt_batch,_ = next(tgt_gen)\n",
    "    \n",
    "    def fit(self, source_train_gen, target_train_gen, source_val_data_loader, target_val_data_loader,\n",
    "            optimizer, epochs=15):\n",
    "        print(f'Training for {epochs} epochs')\n",
    "        CORAL_loss_all = []\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            torch.cuda.empty_cache()  # clear memory to keep stuff from blocking up\n",
    "            \n",
    "            print(\"=== Epoch \" + str(epoch + 1) + \" ===\")\n",
    "            print(\"Training...\")\n",
    "            self.train()\n",
    "            \n",
    "            # using a batch size of 1 here because the generator returns\n",
    "            # many examples in each batch\n",
    "            source_train_data_loader = DataLoader(source_train_gen,\n",
    "                               batch_size = 1, shuffle = True)\n",
    "            target_train_data_loader = DataLoader(target_train_gen,\n",
    "                               batch_size = 1, shuffle = True)\n",
    "            \n",
    "            # returns the next batch of shuffled human data\n",
    "            target_train_data_generator = self.loader_to_generator(target_train_data_loader)\n",
    "\n",
    "            train_losses = []\n",
    "            train_BCE_losses = []\n",
    "            train_CORAL_losses = []\n",
    "            train_preds = []\n",
    "            train_labels = []\n",
    "            for batch_i, data in enumerate(tqdm(source_train_data_loader)):\n",
    "#                 for p in model.parameters():\n",
    "#                     print(p)\n",
    "                seqs_onehot_batch, labels_batch = data\n",
    "                \n",
    "                # reset the optimizer; need to do each batch after weight update\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # push batch through model, get predictions, and calculate loss\n",
    "                preds = self(seqs_onehot_batch.squeeze().cuda())\n",
    "                labels_batch = labels_batch.squeeze()\n",
    "                BCE_loss_batch = self.BCE_loss(preds, labels_batch.cuda())\n",
    "                CORAL_loss_batch = self.CORAL_loss(seqs_onehot_batch, target_train_data_generator, self.conv)\n",
    "#                 CORAL_loss_batch.requires_grad=True\n",
    "\n",
    "                # backpropagate the loss and update model weights accordingly\n",
    "                total_loss_batch = CORAL_loss_batch # BCE_loss_batch # \n",
    "#                 total_loss_batch = self.alpha1 * BCE_loss_batch + self.alpha2 * CORAL_loss_batch\n",
    "#                 print('total loss:', total_loss)\n",
    "#                 print(f'BCE: {BCE_loss_batch}, CORAL: {CORAL_loss_batch}')\n",
    "#                 CORAL_loss_batch.backward()\n",
    "                total_loss_batch.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_losses.append(total_loss_batch.item())\n",
    "                train_BCE_losses.append(BCE_loss_batch.item())\n",
    "                train_CORAL_losses.append(CORAL_loss_batch.item())\n",
    "                train_labels.extend(labels_batch)\n",
    "                train_preds.extend(preds.cpu().detach().numpy())\n",
    "#                 summary_writer.add_scalar(\"Loss/train/CORAL\", CORAL_loss_batch.item(), batch_i + epoch * 400) # 400 is batch size for train TODO get rid of magic number\n",
    "#                 summary_writer.add_scalar(\"Loss/train/BCE\", BCE_loss_batch.item(), batch_i + epoch * 400) # 400 is batch size for train TODO get rid of magic number\n",
    "#                 summary_writer.add_scalar(\"Loss/train/total\", total_loss_batch.item(), batch_i + epoch * 400) # 400 is batch size for train TODO get rid of magic number\n",
    "\n",
    "#                 print('train CORAL loss:', train_CORAL_losses[-1])\n",
    "#                 if batch_i > BREAK_AFTER:\n",
    "#                     break\n",
    "            CORAL_loss_all.extend(train_CORAL_losses)\n",
    "            self.train_loss_by_epoch.append(np.mean(train_losses))\n",
    "            self.train_BCE_loss_by_epoch.append(np.mean(train_BCE_losses))\n",
    "            self.train_CORAL_loss_by_epoch.append(np.mean(train_CORAL_losses))\n",
    "            \n",
    "            print(f'avg total loss: {self.train_loss_by_epoch[-1]}')\n",
    "            print(f'avg BCE   loss: {self.train_BCE_loss_by_epoch[-1]}')\n",
    "            print(f'avg CORAL loss: {self.train_CORAL_loss_by_epoch[-1]}')\n",
    "            \n",
    "            print_metrics(train_preds, train_labels)\n",
    "            \n",
    "            # load new set of negative examples for next epoch\n",
    "            source_train_gen.on_epoch_end()\n",
    "            \n",
    "            # TODO plot train CORAL loss by batches ?        \n",
    "#             summary_writer.flush()\n",
    "            \n",
    "            # Since we don't use gradients during model evaluation,\n",
    "            # the following two lines let the model predict for many examples\n",
    "            # more efficiently (without having to keep track of gradients)\n",
    "#             return CORAL_loss_all\n",
    "            \n",
    "            continue\n",
    "            \n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                # Assess model performance on same-species validation set\n",
    "                print(\"\\nEvaluating on source validation data...\")\n",
    "                \n",
    "                source_val_losses, source_val_preds, source_val_labels = self.validation(source_val_data_loader)\n",
    "\n",
    "                print(\"Source validation loss:\", np.mean(source_val_losses))\n",
    "                self.source_val_loss_by_epoch.append(np.mean(source_val_losses))\n",
    "\n",
    "                # calc auPRC over source validation set\n",
    "                source_val_auprc = print_metrics(source_val_preds, source_val_labels)\n",
    "                self.source_val_auprc_by_epoch.append(source_val_auprc)\n",
    "\n",
    "                # check if this is the best performance we've seen so far\n",
    "                # if yes, save the model weights -- we'll use the best model overall\n",
    "                # for later analyses\n",
    "                if source_val_auprc < self.best_auprc_so_far:\n",
    "                    self.best_auprc_so_far = source_val_auprc\n",
    "                    self.best_state_so_far = self.state_dict()\n",
    "                \n",
    "                \n",
    "                # now repeat for target species data \n",
    "                print(\"\\nEvaluating on target validation data...\")\n",
    "                \n",
    "                target_val_losses, target_val_preds, target_val_labels = self.validation(target_val_data_loader)\n",
    "\n",
    "                print(\"Target validation loss:\", np.mean(target_val_losses))\n",
    "                self.target_val_loss_by_epoch.append(np.mean(target_val_losses))\n",
    "\n",
    "                # calc auPRC over source validation set\n",
    "                target_val_auprc = print_metrics(target_val_preds, target_val_labels)\n",
    "                self.target_val_auprc_by_epoch.append(target_val_auprc)\n",
    "                \n",
    "            print(f'End of epoch {epoch + 1}')\n",
    "        \n",
    "        return CORAL_loss_all # , BCE_loss_all, total_loss_all # after all epochs end\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f23d499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LR=0.001\n",
      "  alpha1=1 (BCE),\n",
      "  alpha2=0.076923077 (CORAL)\n",
      "Training for 1 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34955e81cbec46f18bfcb59899c25700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1 ===\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b992e6811d3c4192adc10bb623aecc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg total loss: 3.7117059925860592e-06\n",
      "avg BCE   loss: 2.667461492585175\n",
      "avg CORAL loss: 3.7117059925860592e-06\n",
      "Loss:\t 2.6674615475799976\n",
      "auROC:\t 0.5387398766520415\n",
      "auPRC:\t 0.5269271016971562\n",
      "Confusion Matrix (at t = 0.5):\n",
      " [[  2248 270752]\n",
      " [    76 272924]]\n"
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "ALPHA1 = 1\n",
    "ALPHA2 = 0.076923077\n",
    "LR     = 1e-3\n",
    "BREAK_AFTER = 10\n",
    "print(f'  LR={LR}\\n  alpha1={ALPHA1} (BCE),\\n  alpha2={ALPHA2} (CORAL)')\n",
    "# summary_writer = SummaryWriter()\n",
    "model = BasicModel(alpha1=ALPHA1, alpha2=ALPHA2, summary_writer=None) # 0, 100_000_000, np.inf\n",
    "model.load_state_dict(torch.load('../models/baseline'))\n",
    "# model = BasicModel() # setting alphas in the code for now\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "# model.load_state_dict(Â torch.load('../models/baseline'))\n",
    "model.cuda()\n",
    "CORAL_loss_all = model.fit(source_train_gen, target_train_gen, source_val_data_loader, target_val_data_loader, optimizer, epochs = 1)\n",
    "model.cpu()\n",
    "# summary_writer.close()\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "run_name = f'coral-{timestamp}-lr_{LR}-alpha_{ALPHA2}'\n",
    "torch.save(model.state_dict(), '../models/' + run_name)\n",
    "# with open(f'../logs/coral-alpha_{ALPHA}_{timestamp}.txt', 'w') as file:\n",
    "#     file.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f9a2e82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3554685587319126e-08"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(loss, run_name):\n",
    "    plt.plot(loss)\n",
    "    y = loss\n",
    "    x = range(len(loss))\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    plt.plot(x, m*x + b)\n",
    "    plt.savefig('../figures/' + run_name + '.jpg')\n",
    "    return m\n",
    "\n",
    "plot_loss(CORAL_loss_by_epoch, run_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "187dd22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20211207T161219\n"
     ]
    }
   ],
   "source": [
    "# print(model.conv.weight.grad)\n",
    "timestamp = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "print(timestamp)\n",
    "run_name = f'coral-{timestamp}_alpha_{ALPHA2}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f504e51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45676821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST tqdm\n",
    "# import time\n",
    "# d = {0:1, 1:2, 2:3, 3:4, 4:5}\n",
    "# l = [(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0)]\n",
    "# def fn():\n",
    "#     for k,v in tqdm(l):\n",
    "#         time.sleep(0.1)\n",
    "\n",
    "# for i in tqdm(range(20)):\n",
    "#     fn()\n",
    "\n",
    "# %%capture cap --no-stderr\n",
    "# print('yay')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs197-env] *",
   "language": "python",
   "name": "conda-env-cs197-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
