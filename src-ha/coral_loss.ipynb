{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de53cd8a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb1ed6f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"  # either 3 or 6\n",
    "\n",
    "from data_generators import *\n",
    "from utils import *\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed3a88d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1365\n",
      "1370\n"
     ]
    }
   ],
   "source": [
    "# setup generators / data loaders for training and validation\n",
    "\n",
    "# we'll make the training data loader in the training loop,\n",
    "# since we need to update some of the examples used each epoch\n",
    "source_train_gen = TrainGenerator(\"mouse\", \"CTCF\")\n",
    "target_train_gen = TrainGenerator(\"human\", \"CTCF\")\n",
    "\n",
    "source_val_gen = ValGenerator(\"mouse\", \"CTCF\")\n",
    "# using a batch size of 1 here because the generator returns\n",
    "# many examples in each batch\n",
    "source_val_data_loader = DataLoader(source_val_gen, batch_size = 1, shuffle = False)\n",
    "\n",
    "target_val_gen = ValGenerator(\"human\", \"CTCF\")\n",
    "target_val_data_loader = DataLoader(target_val_gen, batch_size = 1, shuffle = False) # why would shuffle=True mess with the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "285fd726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_diff = lambda A, B: [np.linalg.norm(a - b) for (a,b) in zip(A,B)]\n",
    "# cov = lambda data, convolve: np.cov(torch.max(convolve(data.squeeze().cuda()), 2).values.T.cpu().detach().numpy())\n",
    "\n",
    "norm_diff = lambda A, B: [torch.linalg.norm(a - b) for (a,b) in zip(A,B)]\n",
    "cov = lambda data, convolve: torch_cov(torch.max(convolve(data.squeeze().cuda()), 2).values.T)\n",
    "\n",
    "def loader_to_generator(data_loader):\n",
    "    for batch in data_loader:\n",
    "        yield batch\n",
    "\n",
    "def CORAL_loss(src_batch, tgt_gen, convolve):\n",
    "    # TODO need to handle case where we have more source than target data and next() returns None\n",
    "    tgt_batch, tgt_labels = next(tgt_gen)\n",
    "    a = cov(src_batch, convolve)\n",
    "    b = cov(tgt_batch, convolve)\n",
    "    d = a.shape[0]\n",
    "    loss = torch.tensor(norm_diff(a, b)).cuda() / (4 * d * d)\n",
    "    return torch.sum(loss) # TODO sum? mean?\n",
    "    # TODO check that each batch is the same as previous\n",
    "\n",
    "# def CORAL_loss_gen(src_gen, tgt_gen, conv_fn):\n",
    "#     src_batch, src_labels = next(src_gen)\n",
    "#     tgt_batch, tgt_labels = next(tgt_gen)\n",
    "#     if src_batch is None or tgt_batch is None:\n",
    "#         return -1\n",
    "#     a = conv_fn(src_batch.squeeze().cuda())\n",
    "#     b = conv_fn(tgt_batch.squeeze().cuda())\n",
    "#     return norm_diff(a, b)\n",
    "\n",
    "class BasicModel(torch.nn.Module):\n",
    "    def __init__(self, alpha1=1., alpha2=0.):\n",
    "        super(BasicModel, self).__init__()\n",
    "        self.input_seq_len = 500\n",
    "        num_conv_filters = 240\n",
    "        lstm_hidden_units = 32\n",
    "        fc_layer1_units = 1024\n",
    "        fc_layer2_units = 512\n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "        \n",
    "        \n",
    "        # Defining the layers to go into our model\n",
    "        # (see the forward function for how they fit together)\n",
    "        self.conv = torch.nn.Conv1d(4, num_conv_filters, kernel_size=20, padding=0)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.maxpool = torch.nn.MaxPool1d(15, stride=15, padding=0)\n",
    "        self.lstm = torch.nn.LSTM(input_size=num_conv_filters,\n",
    "                                  hidden_size=lstm_hidden_units,\n",
    "                                  batch_first=True)\n",
    "        self.fc1 = torch.nn.Linear(in_features=lstm_hidden_units,\n",
    "                                   out_features=fc_layer1_units)\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "        self.fc2 = torch.nn.Linear(in_features=fc_layer1_units,\n",
    "                                   out_features=fc_layer2_units)\n",
    "        self.fc_final = torch.nn.Linear(in_features=fc_layer2_units,\n",
    "                                        out_features=1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.BCE_loss = torch.nn.BCELoss()\n",
    "\n",
    "        # We'll store performance metrics during training in these lists\n",
    "        self.train_loss_by_epoch = []\n",
    "        self.train_BCE_loss_by_epoch = []\n",
    "        self.train_CORAL_loss_by_epoch = []\n",
    "        self.source_val_loss_by_epoch = []\n",
    "        self.source_val_auprc_by_epoch = []\n",
    "        self.target_val_loss_by_epoch = []\n",
    "        self.target_val_auprc_by_epoch = []\n",
    "\n",
    "        # We'll record the best model we've seen yet each epoch\n",
    "        self.best_state_so_far = self.state_dict()\n",
    "        self.best_auprc_so_far = 1\n",
    "\n",
    "#         self.norm_diff = lambda A, B: [np.linalg.norm(a - b) for (a,b) in zip(A,B)]\n",
    "#         self.cov = lambda data: np.cov(torch.max(self(data.squeeze().cuda()), 2).values.T.cpu().detach().numpy())\n",
    "\n",
    "        self.norm_diff = lambda A, B: [torch.linalg.norm(a - b) for (a,b) in zip(A,B)]\n",
    "        self.cov = lambda data: torch_cov(torch.max(self(data.squeeze().cuda()), 2).values.T)\n",
    "\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # return (self.conv(X))\n",
    "        X_1 = self.relu(self.conv(X))\n",
    "        # LSTM is expecting input of shape (batches, seq_len, conv_filters)\n",
    "        X_2 = self.maxpool(X_1).permute(0, 2, 1)\n",
    "        X_3, _ = self.lstm(X_2)\n",
    "        X_4 = X_3[:, -1]  # only need final output of LSTM\n",
    "        X_5 = self.relu(self.fc1(X_4))\n",
    "        X_6 = self.dropout(X_5)\n",
    "        X_7 = self.sigmoid(self.fc2(X_6))\n",
    "        y = self.sigmoid(self.fc_final(X_7)).squeeze()\n",
    "        return y\n",
    "    \n",
    "    def validation(self, data_loader): \n",
    "        # only run this within torch.no_grad() context!\n",
    "        losses = []\n",
    "        preds = []\n",
    "        labels = []\n",
    "        for seqs_onehot_batch, labels_batch in tqdm(data_loader):\n",
    "            # push batch through model, get predictions, calculate loss\n",
    "            preds_batch = self(seqs_onehot_batch.squeeze().cuda())\n",
    "            labels_batch = labels_batch.squeeze()\n",
    "            loss_batch = self.BCE_loss(preds_batch, labels_batch.cuda())\n",
    "            losses.append(loss_batch.item())\n",
    "\n",
    "            # storing labels + preds for auPRC calculation later\n",
    "            labels.extend(labels_batch.detach().numpy())  \n",
    "            preds.extend(preds_batch.cpu().detach().numpy())\n",
    "            \n",
    "        return np.array(losses), np.array(preds), np.array(labels)\n",
    "\n",
    "    def CORAL_loss_validation(self, source_val_data_loader, target_val_data_loader):\n",
    "        losses = []\n",
    "        tgt_gen = loader_to_generator(target_val_data_loader)\n",
    "        \n",
    "        for seqs_onehot_batch, labels_batch in tqdm(source_val_data_loader):\n",
    "            loss_batch = CORAL_loss(seqs_onehot_batch, tgt_gen, self.conv)\n",
    "            losses.append(loss_batch)\n",
    "        return torch.tensor(losses)\n",
    "#         src_gen = loader_to_generator(source_val_data_loader)\n",
    "#         tgt_gen = loader_to_generator(target_val_data_loader)\n",
    "#         src_batch,_ = next(src_gen)\n",
    "#         tgt_batch,_ = next(tgt_gen)\n",
    "#         while src_batch is not None and tgt_batch is not None:\n",
    "#             CORAL_loss_batch = self.alpha * CORAL_loss(src_batch.squeeze().cuda(), self.conv)\n",
    "#             CORAL_losses.append(CORAL_loss_batch.item())\n",
    "#             src_batch,_ = next(src_gen)\n",
    "#             tgt_batch,_ = next(tgt_gen)\n",
    "    \n",
    "    def fit(self, source_train_gen, target_train_gen, source_val_data_loader, target_val_data_loader,\n",
    "            optimizer, epochs=15):\n",
    "        print(f'Training for {epochs} epochs')\n",
    "        CORAL_loss_all = []\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            torch.cuda.empty_cache()  # clear memory to keep stuff from blocking up\n",
    "            \n",
    "            print(\"=== Epoch \" + str(epoch + 1) + \" ===\")\n",
    "            print(\"Training...\")\n",
    "            self.train()\n",
    "            \n",
    "            # using a batch size of 1 here because the generator returns\n",
    "            # many examples in each batch\n",
    "            source_train_data_loader = DataLoader(source_train_gen,\n",
    "                               batch_size = 1, shuffle = True)\n",
    "            target_train_data_loader = DataLoader(target_train_gen,\n",
    "                               batch_size = 1, shuffle = True)\n",
    "            \n",
    "            # returns the next batch of shuffled human data\n",
    "            target_train_data_generator = loader_to_generator(target_train_data_loader)\n",
    "\n",
    "            train_losses = []\n",
    "            train_BCE_losses = []\n",
    "            train_CORAL_losses = []\n",
    "            train_preds = []\n",
    "            train_labels = []\n",
    "            for seqs_onehot_batch, labels_batch in tqdm(source_train_data_loader):\n",
    "#                 for p in model.parameters():\n",
    "#                     print(p)\n",
    "                    \n",
    "                \n",
    "                # reset the optimizer; need to do each batch after weight update\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # push batch through model, get predictions, and calculate loss\n",
    "                preds = self(seqs_onehot_batch.squeeze().cuda())\n",
    "                labels_batch = labels_batch.squeeze()\n",
    "                BCE_loss_batch = self.BCE_loss(preds, labels_batch.cuda())\n",
    "                CORAL_loss_batch = CORAL_loss(seqs_onehot_batch, target_train_data_generator, self.conv)\n",
    "\n",
    "                # backpropagate the loss and update model weights accordingly\n",
    "                total_loss_batch = self.alpha1 * BCE_loss_batch + self.alpha2 * CORAL_loss_batch\n",
    "#                 print('total loss:', total_loss)\n",
    "#                 print(f'BCE: {BCE_loss_batch}, CORAL: {CORAL_loss_batch}')\n",
    "#                 CORAL_loss_batch.backward()\n",
    "                total_loss_batch.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_losses.append(total_loss_batch.item())\n",
    "                train_BCE_losses.append(BCE_loss_batch.item())\n",
    "                train_CORAL_losses.append(CORAL_loss_batch.item())\n",
    "                train_labels.extend(labels_batch)\n",
    "                train_preds.extend(preds.cpu().detach().numpy())\n",
    "\n",
    "#                 print('train CORAL loss:', train_CORAL_losses[-1])\n",
    "            \n",
    "            CORAL_loss_all.extend(train_CORAL_losses)\n",
    "            self.train_loss_by_epoch.append(np.mean(train_losses))\n",
    "            self.train_BCE_loss_by_epoch.append(np.mean(train_BCE_losses))\n",
    "            self.train_CORAL_loss_by_epoch.append(np.mean(train_CORAL_losses))\n",
    "            \n",
    "            print(f'avg total loss: {self.train_loss_by_epoch[-1]}')\n",
    "            print(f'avg BCE   loss: {self.train_BCE_loss_by_epoch[-1]}')\n",
    "            print(f'avg CORAL loss: {self.train_CORAL_loss_by_epoch[-1]}')\n",
    "            \n",
    "            print_metrics(train_preds, train_labels)\n",
    "            \n",
    "            # load new set of negative examples for next epoch\n",
    "            source_train_gen.on_epoch_end()\n",
    "            \n",
    "            # TODO plot train CORAL loss by batches ? \n",
    "            \n",
    "            \n",
    "            \n",
    "            # Since we don't use gradients during model evaluation,\n",
    "            # the following two lines let the model predict for many examples\n",
    "            # more efficiently (without having to keep track of gradients)\n",
    "#             return CORAL_loss_all\n",
    "            \n",
    "            continue\n",
    "            \n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                # Assess model performance on same-species validation set\n",
    "                print(\"\\nEvaluating on source validation data...\")\n",
    "                \n",
    "                source_val_losses, source_val_preds, source_val_labels = self.validation(source_val_data_loader)\n",
    "\n",
    "                print(\"Source validation loss:\", np.mean(source_val_losses))\n",
    "                self.source_val_loss_by_epoch.append(np.mean(source_val_losses))\n",
    "\n",
    "                # calc auPRC over source validation set\n",
    "                source_val_auprc = print_metrics(source_val_preds, source_val_labels)\n",
    "                self.source_val_auprc_by_epoch.append(source_val_auprc)\n",
    "\n",
    "                # check if this is the best performance we've seen so far\n",
    "                # if yes, save the model weights -- we'll use the best model overall\n",
    "                # for later analyses\n",
    "                if source_val_auprc < self.best_auprc_so_far:\n",
    "                    self.best_auprc_so_far = source_val_auprc\n",
    "                    self.best_state_so_far = self.state_dict()\n",
    "                \n",
    "                \n",
    "                # now repeat for target species data \n",
    "                print(\"\\nEvaluating on target validation data...\")\n",
    "                \n",
    "                target_val_losses, target_val_preds, target_val_labels = self.validation(target_val_data_loader)\n",
    "\n",
    "                print(\"Target validation loss:\", np.mean(target_val_losses))\n",
    "                self.target_val_loss_by_epoch.append(np.mean(target_val_losses))\n",
    "\n",
    "                # calc auPRC over source validation set\n",
    "                target_val_auprc = print_metrics(target_val_preds, target_val_labels)\n",
    "                self.target_val_auprc_by_epoch.append(target_val_auprc)\n",
    "                \n",
    "            print(f'End of epoch {epoch + 1}')\n",
    "        \n",
    "        return CORAL_loss_all # after all epochs end\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f23d499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LR=1e-05\n",
      "  alpha1=1 (BCE),\n",
      "  alpha2=0.076923077 (CORAL)\n",
      "Training for 10 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b3246d3b1a4bdb8b7b65c474b28ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1 ===\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588edd0aeb1d4f67b613fec0bcab8b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg total loss: 0.179276261868931\n",
      "avg BCE   loss: 0.17926901742652224\n",
      "avg CORAL loss: 9.417772517925907e-05\n",
      "Loss:\t 0.17926902153214747\n",
      "auROC:\t 0.9795298270673163\n",
      "auPRC:\t 0.9798986766241982\n",
      "Confusion Matrix (at t = 0.5):\n",
      " [[256329  16671]\n",
      " [ 20146 252854]]\n",
      "=== Epoch 2 ===\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8c9716fabb47b4a441294479a35787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg total loss: 0.17526095859952026\n",
      "avg BCE   loss: 0.1752535594361169\n",
      "avg CORAL loss: 9.619081749486133e-05\n",
      "Loss:\t 0.17525356338306944\n",
      "auROC:\t 0.9803916971984059\n",
      "auPRC:\t 0.9807926248657072\n",
      "Confusion Matrix (at t = 0.5):\n",
      " [[256684  16316]\n",
      " [ 19399 253601]]\n",
      "=== Epoch 5 ===\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a309ee09e8b14b559fd8cd66fa98010a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg total loss: 0.17221063406585338\n",
      "avg BCE   loss: 0.17220311422487755\n",
      "avg CORAL loss: 9.775795972131657e-05\n",
      "Loss:\t 0.1722031182458356\n",
      "auROC:\t 0.9810526469159656\n",
      "auPRC:\t 0.9813914262391671\n",
      "Confusion Matrix (at t = 0.5):\n",
      " [[256843  16157]\n",
      " [ 18948 254052]]\n",
      "=== Epoch 8 ===\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b91f2b06914f1dbe4d0d87ee20daeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg total loss: 0.16969995972437737\n",
      "avg BCE   loss: 0.1696923486206121\n",
      "avg CORAL loss: 9.894392999710392e-05\n",
      "Loss:\t 0.16969235210649228\n",
      "auROC:\t 0.9815390795797609\n",
      "auPRC:\t 0.9818788292123524\n",
      "Confusion Matrix (at t = 0.5):\n",
      " [[257072  15928]\n",
      " [ 18587 254413]]\n"
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "ALPHA1 = 1\n",
    "ALPHA2 = 0.076923077\n",
    "LR     = 1e-5\n",
    "print(f'  LR={LR}\\n  alpha1={ALPHA1} (BCE),\\n  alpha2={ALPHA2} (CORAL)')\n",
    "\n",
    "model = BasicModel(alpha1=ALPHA1, alpha2=ALPHA2) # 0, 100_000_000, np.inf\n",
    "model.load_state_dict(torch.load('../models/baseline'))\n",
    "# model = BasicModel() # setting alphas in the code for now\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "# model.load_state_dict(torch.load('../models/baseline'))\n",
    "model.cuda()\n",
    "CORAL_loss_all = model.fit(source_train_gen, target_train_gen, source_val_data_loader, target_val_data_loader, optimizer, epochs = 10)\n",
    "model.cpu()\n",
    "timestamp = datetime.now().strftime('%Y%m%dT%H%M%S')\n",
    "torch.save(model.state_dict(), f'../models/coral-alpha_{ALPHA2}_{timestamp}')\n",
    "# with open(f'../logs/coral-alpha_{ALPHA}_{timestamp}.txt', 'w') as file:\n",
    "#     file.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45676821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "# TEST tqdm\n",
    "# import time\n",
    "# d = {0:1, 1:2, 2:3, 3:4, 4:5}\n",
    "# l = [(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0),(0,0)]\n",
    "# def fn():\n",
    "#     for k,v in tqdm(l):\n",
    "#         time.sleep(0.1)\n",
    "\n",
    "# for i in tqdm(range(20)):\n",
    "#     fn()\n",
    "\n",
    "%%capture cap --no-stderr\n",
    "print('yay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9a2e82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9723bd9e50>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(CORAL_loss_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187dd22a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs197-env] *",
   "language": "python",
   "name": "conda-env-cs197-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
