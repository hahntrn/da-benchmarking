{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de53cd8a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb1ed6f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"  # either 3 or 6\n",
    "\n",
    "from data_generators import *\n",
    "import utils\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3a88d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1365\n"
     ]
    }
   ],
   "source": [
    "# setup generators / data loaders for training and validation\n",
    "\n",
    "# we'll make the training data loader in the training loop,\n",
    "# since we need to update some of the examples used each epoch\n",
    "train_gen = TrainGenerator(\"mouse\", \"CTCF\")\n",
    "\n",
    "source_val_gen = ValGenerator(\"mouse\", \"CTCF\")\n",
    "# using a batch size of 1 here because the generator returns\n",
    "# many examples in each batch\n",
    "source_val_data_loader = DataLoader(source_val_gen, batch_size = 1, shuffle = True)\n",
    "\n",
    "target_val_gen = ValGenerator(\"human\", \"CTCF\")\n",
    "target_val_data_loader = DataLoader(target_val_gen, batch_size = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a17a1",
   "metadata": {},
   "source": [
    "# Model Training And Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285fd726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicModel, self).__init__()\n",
    "        self.input_seq_len = 500\n",
    "        num_conv_filters = 240\n",
    "        lstm_hidden_units = 32\n",
    "        fc_layer1_units = 1024\n",
    "        fc_layer2_units = 512\n",
    "        \n",
    "        # Defining the layers to go into our model\n",
    "        # (see the forward function for how they fit together)\n",
    "        self.conv = torch.nn.Conv1d(4, num_conv_filters, kernel_size=20, padding=0)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        # We'll store performance metrics during training in these lists\n",
    "        self.train_loss_by_epoch = []\n",
    "        self.source_val_loss_by_epoch = []\n",
    "        self.source_val_auprc_by_epoch = []\n",
    "        self.target_val_loss_by_epoch = []\n",
    "        self.target_val_auprc_by_epoch = []\n",
    "\n",
    "        # We'll record the best model we've seen yet each epoch\n",
    "        self.best_state_so_far = self.state_dict()\n",
    "        self.best_auprc_so_far = 1\n",
    "\n",
    "    def forward(self, X):\n",
    "        return (self.conv(X))\n",
    "        \n",
    "    def validation(self, data_loader):\n",
    "        # only run this within torch.no_grad() context!\n",
    "        losses = []\n",
    "        preds = []\n",
    "        labels = []\n",
    "        for seqs_onehot_batch, labels_batch in data_loader:\n",
    "            # push batch through model, get predictions, calculate loss\n",
    "            preds_batch = self(seqs_onehot_batch.squeeze().cuda())\n",
    "            labels_batch = labels_batch.squeeze()\n",
    "            loss_batch = self.loss(preds_batch, labels_batch.cuda())\n",
    "            losses.append(loss_batch.item())\n",
    "\n",
    "            # storing labels + preds for auPRC calculation later\n",
    "            labels.extend(labels_batch.detach().numpy())  \n",
    "            preds.extend(preds_batch.cpu().detach().numpy())\n",
    "            \n",
    "        return np.array(losses), np.array(preds), np.array(labels)\n",
    "\n",
    "    def convolve(self, data_loader):\n",
    "        # only run this within torch.no_grad() context!\n",
    "\n",
    "        # DEBUG\n",
    "        for seqs_onehot_batch, labels_batch in data_loader:\n",
    "            print('seqs_onehot_batch:',seqs_onehot_batch.shape)\n",
    "            print('labels_batch:', labels_batch.shape)\n",
    "            break\n",
    "            \n",
    "        features = []\n",
    "        for seqs_onehot_batch, labels_batch in data_loader:\n",
    "            # push batch through model, get predictions, calculate loss\n",
    "            features_batch = self(seqs_onehot_batch.squeeze().cuda())\n",
    "            print(features_batch.shape)\n",
    "            # storing labels + preds for auPRC calculation later\n",
    "            features.extend(features_batch.cpu().detach().numpy())\n",
    "#             features.extend(features_batch.cpu().detach().numpy())\n",
    "        features_all = np.array(features)\n",
    "        print('features:',features_all.shape)\n",
    "        return features_all # maybe hold off on converting to numpy to run torch.cov on the gpu?\n",
    "    \n",
    "    def loader_to_generator(self, data_loader):\n",
    "        for batch in data_loader:\n",
    "            yield batch\n",
    "    \n",
    "    def get_cov(self, data_loader, nbatch=100):\n",
    "        \"\"\"\n",
    "        seqs_onehot_batch : (1, batchsize, input_seq_len) [1, 1000, 4, 500]\n",
    "        convolved_batch : (batchsize, num_conv_filters, input_seq_len - padding) [1000, 240, 481]\n",
    "        labels_batch : (1, batchsize) [1, 1000]\n",
    "        cov_batch : ()\n",
    "        \"\"\"\n",
    "        covariances = []\n",
    "        generator = self.loader_to_generator(data_loader)\n",
    "        for i in range(nbatch):\n",
    "            seqs_onehot_batch, labels_batch = next(generator)\n",
    "            # push batch through model, get predictions, calculate loss\n",
    "            convolved_batch = self(seqs_onehot_batch.squeeze().cuda())\n",
    "            cov_batch = np.cov(torch.max(convolved_batch, 2).values.T.cpu().detach().numpy())\n",
    "            covariances.append(cov_batch)\n",
    "        print(f'cov of batch {i-nbatch+1} to {i+1}')\n",
    "        return covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f23d499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting covariances for source and target...\n",
      "cov of batch 0 to 100\n",
      "cov of batch 0 to 100\n",
      "cov of batch 0 to 100\n",
      "cov of batch 0 to 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BasicModel(\n",
       "  (conv): Conv1d(4, 240, kernel_size=(20,), stride=(1,))\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BasicModel()\n",
    "model.cuda()\n",
    "print('Getting covariances for source and target...')\n",
    "src_cov0 = model.get_cov(source_val_data_loader)\n",
    "src_cov1 = model.get_cov(source_val_data_loader)\n",
    "tgt_cov0 = model.get_cov(target_val_data_loader)\n",
    "tgt_cov1 = model.get_cov(target_val_data_loader)\n",
    "model.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55430fe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_diff = lambda A, B: [np.linalg.norm(a - b) for (a,b) in zip(A,B)]\n",
    "\n",
    "mm = norm_diff(src_cov0, src_cov1)\n",
    "# print(mm)\n",
    "hm = norm_diff(src_cov0, tgt_cov0)\n",
    "hh = norm_diff(tgt_cov0, tgt_cov1)\n",
    "same = norm_diff(tgt_cov0, tgt_cov0)\n",
    "len(tgt_cov1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a51ed183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_filters(first, second):\n",
    "#     src_cov0, tgt_cov0\n",
    "#     src_cov1, tgt_cov1 (2nd batch)\n",
    "    norm_diff = lambda A, B: [np.abs(a - b) for (a,b) in zip(A,B)]\n",
    "    a = norm_diff(first, second)\n",
    "#     print(a)\n",
    "    mxm = a[0][0][0]\n",
    "    sol = []\n",
    "    for x in a:\n",
    "        r = 0\n",
    "        for y in x:\n",
    "            r += 1\n",
    "            c = 0\n",
    "            for z in y:\n",
    "                c += 1\n",
    "                if z > mxm and c != r:\n",
    "                    print(z, r, c)\n",
    "                    mxm = z\n",
    "                    current = [r, c]\n",
    "        sol.append(current)\n",
    "    return sol\n",
    "#         print(x, x.shape)\n",
    "#         y = max(x)\n",
    "#         print('y', y)\n",
    "#         [b, c] = find(x==y)\n",
    "#         print(b)\n",
    "#     for argmax(norm_diff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52e889fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010614227978413627 1 8\n",
      "0.0012787100967042845 1 134\n",
      "0.001473694730517875 5 115\n",
      "0.0019333227528645562 6 40\n",
      "0.0020820605894279766 23 237\n",
      "0.0025105248692933765 78 170\n",
      "0.002819291001709281 78 237\n",
      "0.002994904467489385 115 237\n",
      "0.00362380436673034 170 229\n",
      "0.0036914136278066887 170 229\n",
      "0.00409084866164753 170 237\n",
      "0.004348053816750737 170 229\n",
      "0.004458256049004624 170 229\n",
      "0.004481234460351122 170 229\n",
      "0.004723527660906041 170 237\n",
      "0.004803111776171495 170 229\n",
      "0.005136398360022255 170 229\n",
      "0.005161311754171217 170 229\n",
      "[[78, 237], [170, 229], [170, 229], [170, 229], [170, 237], [170, 237], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 237], [170, 237], [170, 237], [170, 237], [170, 237], [170, 237], [170, 237], [170, 237], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229], [170, 229]]\n"
     ]
    }
   ],
   "source": [
    "print(get_conv_filters(src_cov0, tgt_cov0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a4b77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  6.,  1.,  6.,  8., 10., 15., 11., 11.,  7.,  1., 13.,  3.,\n",
       "         2.,  2.,  2.,  0.,  0.,  0.,  1.]),\n",
       " array([0.09313191, 0.09389735, 0.09466278, 0.09542822, 0.09619366,\n",
       "        0.09695909, 0.09772453, 0.09848997, 0.0992554 , 0.10002084,\n",
       "        0.10078628, 0.10155172, 0.10231715, 0.10308259, 0.10384803,\n",
       "        0.10461346, 0.1053789 , 0.10614434, 0.10690977, 0.10767521,\n",
       "        0.10844065]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(hm, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d611754",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mm, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19370f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hh, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a906f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(same, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'human-human ~ N({np.mean(hh)}, {np.std(hh)}^2)')\n",
    "print(f'human-mouse ~ N({np.mean(hm)}, {np.std(hm)}^2)')\n",
    "print(f'mouse-mouse ~ N({np.mean(mm)}, {np.std(mm)}^2)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs197-env] *",
   "language": "python",
   "name": "conda-env-cs197-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
